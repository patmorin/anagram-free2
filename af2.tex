\documentclass{patmorin}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,wrapfig}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{amsthm,mathtools}
\usepackage{pat}
\usepackage{paralist}
\usepackage{stmaryrd}
\usepackage[noend,]{algorithmic}
% \usepackage{thm-restate}

% \usepackage[longnamesfirst,numbers,sort&compress]{natbib}
% \usepackage[noabbrev,capitalise]{cleveref}

\usepackage{doi} % To make plainnat handle doi's properly 


\usepackage[mathlines]{lineno}
% \setlength{\linenumbersep}{2em}
% \linenumbers
% \rightlinenumbers
% \linenumbers
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
 \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
 \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
 \renewenvironment{#1}%
    {\linenomath\csname old#1\endcsname}%
    {\csname oldend#1\endcsname\endlinenomath}}% 
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
 \patchAmsMathEnvironmentForLineno{#1}%
 \patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
\patchBothAmsMathEnvironmentsForLineno{flalign}%
\patchBothAmsMathEnvironmentsForLineno{alignat}%
\patchBothAmsMathEnvironmentsForLineno{gather}%
\patchBothAmsMathEnvironmentsForLineno{multline}%
}

\setlength{\parskip}{1ex}

\newcommand{\floor}[1]{\lfloor #1\rfloor}

\title{\MakeUppercase{Anagram-Free Sequences via Entropy Compression}}
\author{The Armenian Gang}




\begin{document}
\maketitle

\begin{abstract}
  We show that arbitrarily long anagram-free sequences (also known as strongly-non-repetitive sequences) over a small alphabet can be generated using a simple randomized algorithm.
\end{abstract}

\section{Introduction}

A string $s_1,\ldots,s_{2k}$ is an \emph{anagram} if $s_1,\ldots,s_k$ is a permutation of $s_{k+1},\ldots,s_{2k}$.  A string $s_1,\ldots,s_n$ is \emph{anagram-free} if it contains no (consecutive) substring that is an anagram.  We say that a string is $\ge k$-anagram-free if it contains no substring of length at least $k$ that is an anagram.

Consider the following algorithm for generating $\ge k$-anagram-free strings over an alphabet $\Sigma$ with $|\Sigma|=c$:

\noindent$\textsc{Anagram-Free}(m, k, \Sigma)$:
\begin{algorithmic}[1]
  \STATE{$n\gets 0$}
  \FOR{$i\gets 1,\ldots,m$}
    \STATE{$x_i \gets \text{a uniformly random element in $\Sigma$}$}
    \STATE{$s_{n+1}\gets x_i$}
    \STATE{$n\gets n+1$}
    \STATE{Let $t$ be the largest integer such that $s_{n-2t+1},\ldots,s_n$ is an anagram}
    \STATE{$n\gets n-t$}
  \ENDFOR
  \RETURN{$s_1,\ldots,s_n$}
\end{algorithmic}

The preceding algorithm clearly returns an anagram free string.  We wish to show that, for sufficiently large $\Sigma$, $\textsc{Anagram-Free}(m, k, \Sigma)$ (typically) returns a string whose length, $n$, is linear in the number, $m$, of iterations.

Note that, when the algorithm returns in Line~8, it returns a string of length
\begin{equation}  
  n = m - \sum_{i=1}^m t_i  \eqlabel{sumsize}
\end{equation}
since each iteration $i\in\{1,\ldots,m\}$ increments $n$ (Line~5) and decreases $n$ by $t_i$ (Line~7) during iteration $i$.

\section{The Encoding Scheme}

We now describe an encoding scheme that traces the execution of $\textsc{Anagram-Free}(m, k, \Sigma)$ and outputs a sequence of bits that allows us to recover the random string $x_1,\ldots,x_m$.  If the algorithm produces an output of length $n < \epsilon m$ then the length of the encoding will be less than $m\log c$.  Since $x_1,\ldots,x_m$ is uniformly random over $|\Sigma|^m$---a set of size $c^m$---the probability that it can be encoded using $m\log c - t$ or fewer bits is at most $2^{-t}$.

We use the phrase ``encoding scheme'' loosely here.  In particular, we will make use of ``codes'' where codewords have non-integer lengths, sometimes even having lengths much less than 1.  We are only doing this for the sake of analysis and all our results could be restated in terms of probabilities, though possibly less intuitively.

We say that a sequence of positive numbers $\langle \ell_i : i\in\Z_{\ge 0}\rangle$ satisfies \emph{Kraft's Inequality} if $\sum_{i\in\Z_{\ge 0}} 2^{-\ell_i} \le 1$.  In this work, we will use binary codes for non-negative integers in which the ``codeword'' for each $i\in\Z_{\ge 0}$ has length $\ell_i$.  Although non-intuitive, this can be rigorously justified so long as the codeword lengths satisfy Kraft's Inequality \cite[Section~7]{morin.mulzer.ea:encoding}.

Critical to this work is a code for non-negative integers whose codeword lengths $\langle \ell_i:i\in\Z_{\ge0}\rangle$ are carefully balanced in order to satisfy Kraft's Inequality in addition to some other requirements.  In this code, the codeword for 0 has length
\[
     \ell_0 = \frac{(1+\beta)\log e}{c}
\]
for some $\beta >0$.  We will specify the value of $\ell_i$ for $i>0$ as our exposition unfolds.

\subsection{Encoding}

To encode $c_1,\ldots,c_m$, we encode the following information:
\begin{enumerate}
  \item The string $s_1,\ldots,s_n$ returned by algorithm in Line~8 using $n\log c$ bits.
  \item The sequence $t_1,\ldots,t_m$ of deletions using $\sum_{i=1}^m \ell_{t_i}$ bits.
  \item A sequence $\xi_1,\ldots,\xi_m$ where each $\xi_i$ contains enough information to recover the $t_i$ values deleted from $s$ during iteration $i$.
\end{enumerate}

The number of bits required for the third item is the subject of \secref{something}, where we will show that the number of bits required for $\xi_i$ is at most
\begin{equation}
   |\xi_i| 
   \le \begin{cases}
     0 & \text{if $t_i=0$} \\
     t_i(\log c - (1+\epsilon)\ell_0) - \ell_{t_i} 
        & \text{otherwise}
   \end{cases}  \eqlabel{xi-i}
\end{equation}
for some $\epsilon > 0$.

Let $I_0=\{i\in\{1,\ldots,m\}: t_i=0\}$ and let $I_{>0}=\{1,\ldots,m\}\setminus I_0$.
It follows that the number of bits used in this encoding is
\begin{align*}
    |C| 
    & = n\log c + \sum_{i\in I_0} \ell_0
       + \sum_{i\in I_{>0}} (|\xi_i| + \ell_{t_i}) \\
       & = n\log c + |I_0|\ell_0
          + \sum_{i\in I_{>0}} t_i(\log c - (1+\epsilon)\ell_0) \\
       & = m\log c + |I_0|\ell_0
           - \sum_{i\in I_{>0}} t_i(1+\epsilon)\ell_0 \\
       & = m\log c + |I_0|\ell_0
           - (m-n)(1+\epsilon)\ell_0 \\
       & \le m\log c + m\ell_0
           - (m-n)(1+\epsilon)\ell_0 \\
       & \le m\log c - \lambda\ell_0
\end{align*}
for any positive $\lambda$ such that
\[
     n \le \frac{\epsilon m-\lambda}{1+\epsilon} \enspace .
\]
For example, taking $\lambda = c/(1+\beta)$ shows that the probability that the algorithm fails to produce an output of length more than $\frac{\epsilon m-c/(1+\beta)}{1+\epsilon}$ is at most $1/e$.

It still remains to describe the codeword lengths $\langle \ell_i:i\in \N\rangle$ as well the the encodings of $\xi_i$ satisfying \eqref{xi-i}.  Before doing so, we first review how the encoding can be used to recover $x_1,\ldots,x_m$.


\subsection{Decoding}

To recover $x_1,\ldots,x_m$ using this information, we proceed as follows:
\begin{enumerate}
  \item If $t_i=0$ for all $i\in\{1,\ldots,m\}$, then $m=n$ and we immediately deduce that $x_1,\ldots,x_m=s_1,\ldots,s_n$.
  \item Otherwise, we find the minimum value $d$ such that $t_{m-d}\neq 0$.  
  From this we deduce that $x_{m-d+1},\ldots,x_m = s_{n-d+1},\ldots,s_n$.
  \item Since $s_1,\ldots,s_{n-d}$ was the string generated by the algorithm at the end of iteration $i$, immediately after deleting a suffix $s'_{n-d+1},\ldots,s'_{n-d+t_{m-d}}$ of length $t_{m-d}$.
  \item The string $\xi_{m-d}$ contains enough information to recover
  $s'_{n-d+1},\ldots,s'_{n-d+t_{m-d}}$.
  \item We know that $x_{m-d} = s'_{n-d+t_{m-d}}$ triggered the deletion of $t_{m-d}$ elements.
  \item Therefore, at the end of iteration $m-d-1$ the algorithm had constructed the string $s_1,\ldots,s_{n-d},s'_{n-d+1},\ldots,s'_{n-d+t_{m-d}-1}$.
  \item At this point we have recovered $x_{m-d},\ldots,x_m$ as well as the string constructed by the algorithm at the conclusion of iteration $m-d-1$.  We can the proceed inductively using $t_1,\ldots,t_{m-d-1}$, $\xi_1,\ldots,\xi_{m-d-1}$ and $s_1,\ldots,s_{n-d},s'_{n-d+1},\ldots,s'_{n-d+t_{m-d}-1}$ to recover $x_1,\ldots,x_{m-d-1}$.
\end{enumerate}

\subsection{Code Length}

We now describe the rest of the code.

If $t_i=1$, then $s_n=s_{n-1}$ and there is nothing to encode, so $|\xi_1|=0$.  We set $\ell_1=\log c - (1+\epsilon)\ell_0$.

If $t_i=2$, then there is also nothing to encode since $s_{n-3},s_{n-2}=s_{n-1},s_n$. We set $\ell_2=2(\log c - (1+\epsilon)\ell_0)$.

IF $t_i=3$, then $s_{n-3},s_{n-4},s_{n-5}$ are all distinct, and $s_{n-2},s_{n-1},s_n$ is an irreducible permutation of $s_{n-3},s_{n-4},s_{n-5}$.  The number, $a_3$, of irreducible permutations of length 3 is 3, so $|\xi_i|=\log 3$.  We set $\ell_3 = 3(\log c-(1+\epsilon)\ell_0)-\log 3$.

In general, if $t_i=t$ for $t\le c$, $|\xi_i|=\log a_t$ where $a_t$ is the number of irreducible permutations of length $t$. We set $\ell_t = t(\log c - (1+\epsilon)\ell_0) - \log a_t$.



\end{document}
